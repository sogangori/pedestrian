{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import ast\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "visdrone_categories = ['bg','pedestrian', 'person', 'car', 'van', 'bus', 'truck', 'motor', 'bicycle', 'awning-tricycle', 'tricycle','empty_0','empty_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_visDrone = '/home/mvlab/Downloads/dataset/VisDrone2019/VisDrone2019-DET-train/'\n",
    "path_visDrone_annotation = path_visDrone + 'annotations/'\n",
    "path_visDrone_image = path_visDrone + 'images/'\n",
    "os.path.isdir(path_visDrone_annotation), os.path.isdir(path_visDrone_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_visdrone_data(path_visDrone, pedestrian_only=True):\n",
    "    \n",
    "    list_image_arr = []\n",
    "    list_cbbox = []\n",
    "    path_visDrone_annotation = path_visDrone + 'annotations/'\n",
    "    path_visDrone_image = path_visDrone + 'images/'\n",
    "    os.path.isdir(path_visDrone_annotation), os.path.isdir(path_visDrone_image)\n",
    "    list_annotation = glob(path_visDrone_annotation+'*.*')\n",
    "    list_image_path = glob(path_visDrone_image+'*.*')\n",
    "    len(list_annotation), len(list_image_path), list_annotation[0]\n",
    "    \n",
    "    for i in range(len(list_annotation)):\n",
    "        path_annotation = list_annotation[i]\n",
    "        \n",
    "        df = pd.read_csv(path_annotation, header=None)\n",
    "                \n",
    "        cls = np.array(df.iloc[:, 5])\n",
    "        bbox_xywh = np.array(df.iloc[:, :4])\n",
    "        x0 = bbox_xywh[:, 0]\n",
    "        y0 = bbox_xywh[:, 1]\n",
    "        w = bbox_xywh[:, 2]\n",
    "        h = bbox_xywh[:, 3]\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        \n",
    "        file_name_annotation = path_annotation.split('/')[-1].split('.')[0]\n",
    "        file_name_image = path_visDrone_image+file_name_annotation+'.jpg'\n",
    "                \n",
    "        if pedestrian_only:            \n",
    "            human_mask = np.logical_and(cls > 0, cls < 3)\n",
    "            vehicle_mask = cls > 2\n",
    "            is_human_contain = np.any(human_mask)\n",
    "            human_count = np.sum(human_mask)\n",
    "            if not is_human_contain or human_count < 30:#30:651\n",
    "                continue\n",
    "            \n",
    "            cls = np.where(human_mask, 1.0, 0.0)\n",
    "            #cls = np.where(vehicle_mask, 3.0, cls)        \n",
    "        \n",
    "        img = Image.open(file_name_image)\n",
    "        img_arr = np.array(img)\n",
    "        img_h, img_w, img_c = img_arr.shape\n",
    "        cbbox_norm = np.stack((x0/img_w, y0/img_h, x1/img_w, y1/img_h, cls), axis=1)\n",
    "        \n",
    "        if pedestrian_only:\n",
    "            cbbox_norm = cbbox_norm[human_mask]\n",
    "            \n",
    "            box_height = cbbox_norm[:, 3] - cbbox_norm[:, 1]\n",
    "            box_height_max = np.max(box_height)\n",
    "            if box_height_max < 0.05 or box_height_max > 0.2:\n",
    "                continue\n",
    "                \n",
    "        list_image_arr.append(img_arr)\n",
    "        list_cbbox.append(cbbox_norm)\n",
    "        if len(list_image_arr)>1000:\n",
    "            break\n",
    "        if i%100==0:\n",
    "            print(len(list_annotation), i, file_name_annotation, len(list_image_arr))\n",
    "    return list_image_arr, list_cbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6471 1200 0000050_00500_d_0000104 100\n",
      "6471 1500 9999937_00000_d_0000179 125\n",
      "6471 2200 0000351_02941_d_0000534 181\n",
      "6471 3000 0000036_00500_d_0000046 242\n",
      "6471 3300 0000288_03601_d_0000802 274\n",
      "6471 3800 0000358_02353_d_0000692 313\n",
      "6471 4800 0000309_04201_d_0000354 418\n",
      "6471 5700 0000205_01665_d_0000200 505\n",
      "553\n"
     ]
    }
   ],
   "source": [
    "list_visdrone_image_arr, list_visdrone_cbbox = load_visdrone_data(path_visDrone)\n",
    "print(len(list_visdrone_image_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2102., 2609., 3207., 3943., 5123., 5135., 3879., 2873., 2029.,\n",
       "        1504.]),\n",
       " array([0.        , 0.09971429, 0.19942857, 0.29914286, 0.39885714,\n",
       "        0.49857143, 0.59828571, 0.698     , 0.79771429, 0.89742857,\n",
       "        0.99714286]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQFElEQVR4nO3dcaydd13H8ffHFsYUJpu7W2o77DRV6RaH7DobUTPAuLIZOxOWFJU1ZEnjnAYTjXT8ITFmSYkJIVM30iBZF4WlEXAVHNpUEQ1j4zYOum7MXdncmjbrBVQGJjMtX/84P5Jjd9v7dL333N3+3q/k5Hme73mec76/3JtPn/7Oc56bqkKS1IfvWe4GJEmTY+hLUkcMfUnqiKEvSR0x9CWpI6uXu4GFXHzxxbV+/frlbkOSVpQDBw58raqmTq6/7EN//fr1zMzMLHcbkrSiJPmP+epO70hSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkde9t/IlRayfsenl7uFiXt65w3L3YJWKM/0Jakjg0I/ydNJDiZ5JMlMq12UZF+SJ9vywrH9b08ym+SJJNeN1a9urzOb5M4kWfwhSZJO5UzO9N9cVW+oqum2vQPYX1UbgP1tmyQbga3AFcBm4K4kq9oxdwPbgQ3tsfnshyBJGupspne2ALvb+m7gxrH6fVX1QlU9BcwC1yRZA1xQVQ/W6K+x3zt2jCRpAoaGfgF/n+RAku2tdmlVHQVoy0tafS3w7Nixh1ttbVs/uf4iSbYnmUkyMzc3N7BFSdJChl6986aqOpLkEmBfkq+cZt/55unrNPUXF6t2AbsApqen591HknTmBp3pV9WRtjwGfBK4BniuTdnQlsfa7oeBy8YOXwccafV189QlSROyYOgn+b4kr/nuOvCLwKPAXmBb220bcH9b3wtsTXJekssZfWD7cJsCej7JpnbVzs1jx0iSJmDI9M6lwCfb1ZWrgY9W1WeSfBHYk+QW4BngJoCqOpRkD/AYcBy4rapOtNe6FbgHOB94oD0kSROyYOhX1VeBq+apfx146ymOuQO4Y576DHDlmbcpSVoMfiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SODA79JKuS/GuST7Xti5LsS/JkW144tu/tSWaTPJHkurH61UkOtufuTJLFHY4k6XTO5Ez/3cDjY9s7gP1VtQHY37ZJshHYClwBbAbuSrKqHXM3sB3Y0B6bz6p7SdIZGRT6SdYBNwAfHitvAXa39d3AjWP1+6rqhap6CpgFrkmyBrigqh6sqgLuHTtGkjQBQ8/0Pwj8PvCdsdqlVXUUoC0vafW1wLNj+x1utbVt/eT6iyTZnmQmyczc3NzAFiVJC1kw9JP8EnCsqg4MfM355unrNPUXF6t2VdV0VU1PTU0NfFtJ0kJWD9jnTcAvJ7keeBVwQZK/AJ5Lsqaqjrapm2Nt/8PAZWPHrwOOtPq6eeqSpAlZMPSr6nbgdoAk1wK/V1W/nuSPgW3Azra8vx2yF/hokg8AP8joA9uHq+pEkueTbAIeAm4G/mSRx6Nlsn7Hp5e7BUkDDDnTP5WdwJ4ktwDPADcBVNWhJHuAx4DjwG1VdaIdcytwD3A+8EB7SJImJKMLaV6+pqena2ZmZrnb0AI80+/D0ztvWO4WNFCSA1U1fXLdb+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyOrlbkCLa/2OTy93C5JexjzTl6SOGPqS1BFDX5I6YuhLUkcMfUnqyIKhn+RVSR5O8qUkh5L8YatflGRfkifb8sKxY25PMpvkiSTXjdWvTnKwPXdnkizNsCRJ8xlypv8C8Jaqugp4A7A5ySZgB7C/qjYA+9s2STYCW4ErgM3AXUlWtde6G9gObGiPzYs4FknSAhYM/Rr5Vtt8RXsUsAXY3eq7gRvb+hbgvqp6oaqeAmaBa5KsAS6oqgerqoB7x46RJE3AoDn9JKuSPAIcA/ZV1UPApVV1FKAtL2m7rwWeHTv8cKutbesn1+d7v+1JZpLMzM3Nncl4JEmnMSj0q+pEVb0BWMforP3K0+w+3zx9naY+3/vtqqrpqpqempoa0qIkaYAzunqnqv4L+Cyjufjn2pQNbXms7XYYuGzssHXAkVZfN09dkjQhQ67emUry2rZ+PvALwFeAvcC2tts24P62vhfYmuS8JJcz+sD24TYF9HySTe2qnZvHjpEkTcCQG66tAXa3K3C+B9hTVZ9K8iCwJ8ktwDPATQBVdSjJHuAx4DhwW1WdaK91K3APcD7wQHtIkiYkowtpXr6mp6drZmZmudtYMbzLps5FT++8YblbWHGSHKiq6ZPrfiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeG3HtHZ8hbIUh6ufJMX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIOf03cv1btZL0/y14pp/ksiT/mOTxJIeSvLvVL0qyL8mTbXnh2DG3J5lN8kSS68bqVyc52J67M0mWZliSpPkMmd45DvxuVb0e2ATclmQjsAPYX1UbgP1tm/bcVuAKYDNwV5JV7bXuBrYDG9pj8yKORZK0gAWnd6rqKHC0rT+f5HFgLbAFuLbtthv4LPCeVr+vql4AnkoyC1yT5Gnggqp6ECDJvcCNwAOLOB5J56DlnKp9eucNy/beS+GMPshNsh74SeAh4NL2D8J3/2G4pO22Fnh27LDDrba2rZ9cn+99tieZSTIzNzd3Ji1Kkk5jcOgneTXwceB3quqbp9t1nlqdpv7iYtWuqpququmpqamhLUqSFjAo9JO8glHg/2VVfaKVn0uypj2/BjjW6oeBy8YOXwccafV189QlSRMy5OqdAH8OPF5VHxh7ai+wra1vA+4fq29Ncl6Syxl9YPtwmwJ6Psmm9po3jx0jSZqAIdfpvwl4J3AwySOt9l5gJ7AnyS3AM8BNAFV1KMke4DFGV/7cVlUn2nG3AvcA5zP6ANcPcSVpgoZcvfMvzD8fD/DWUxxzB3DHPPUZ4MozaVCStHi8DYMkdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6siQ++lLUreW64+yL9UfZPdMX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkQVDP8lHkhxL8uhY7aIk+5I82ZYXjj13e5LZJE8kuW6sfnWSg+25O5Nk8YcjSTqdIWf69wCbT6rtAPZX1QZgf9smyUZgK3BFO+auJKvaMXcD24EN7XHya0qSltiCoV9VnwO+cVJ5C7C7re8Gbhyr31dVL1TVU8AscE2SNcAFVfVgVRVw79gxkqQJealz+pdW1VGAtryk1dcCz47td7jV1rb1k+vzSrI9yUySmbm5uZfYoiTpZIv9Qe588/R1mvq8qmpXVU1X1fTU1NSiNSdJvXupof9cm7KhLY+1+mHgsrH91gFHWn3dPHVJ0gS91NDfC2xr69uA+8fqW5Ocl+RyRh/YPtymgJ5PsqldtXPz2DGSpAlZvdAOST4GXAtcnOQw8D5gJ7AnyS3AM8BNAFV1KMke4DHgOHBbVZ1oL3UroyuBzgceaA9J0gQtGPpV9Y5TPPXWU+x/B3DHPPUZ4Moz6k6StKj8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpIxMP/SSbkzyRZDbJjkm/vyT1bKKhn2QV8GfA24CNwDuSbJxkD5LUs0mf6V8DzFbVV6vqf4H7gC0T7kGSurV6wu+3Fnh2bPsw8NMn75RkO7C9bX4ryRMv8f0uBr72Eo9dqRxzHxzzOS7vB85uzD80X3HSoZ95avWiQtUuYNdZv1kyU1XTZ/s6K4lj7oNj7sNSjHnS0zuHgcvGttcBRybcgyR1a9Kh/0VgQ5LLk7wS2ArsnXAPktStiU7vVNXxJL8F/B2wCvhIVR1awrc86ymiFcgx98Ex92HRx5yqF02pS5LOUX4jV5I6YuhLUkfOidBf6NYOGbmzPf/lJG9cjj4X04Ax/1ob65eTfD7JVcvR52IaeguPJD+V5ESSt0+yv6UwZMxJrk3ySJJDSf5p0j0utgG/29+f5G+SfKmN+V3L0ediSfKRJMeSPHqK5xc3v6pqRT8YfSD878APA68EvgRsPGmf64EHGH1PYBPw0HL3PYEx/wxwYVt/Ww9jHtvvH4C/Bd6+3H1P4Of8WuAx4HVt+5Ll7nsCY34v8P62PgV8A3jlcvd+FmP+eeCNwKOneH5R8+tcONMfcmuHLcC9NfIF4LVJ1ky60UW04Jir6vNV9Z9t8wuMvhOxkg29hcdvAx8Hjk2yuSUyZMy/Cnyiqp4BqKqVPu4hYy7gNUkCvJpR6B+fbJuLp6o+x2gMp7Ko+XUuhP58t3ZY+xL2WUnOdDy3MDpTWMkWHHOStcCvAB+aYF9LacjP+UeBC5N8NsmBJDdPrLulMWTMfwq8ntEXOw8C766q70ymvWWxqPk16dswLIUht3YYdPuHFWTweJK8mVHo/+ySdrT0hoz5g8B7qurE6CRwxRsy5tXA1cBbgfOBB5N8oar+bambWyJDxnwd8AjwFuBHgH1J/rmqvrnUzS2TRc2vcyH0h9za4Vy7/cOg8ST5CeDDwNuq6usT6m2pDBnzNHBfC/yLgeuTHK+qv55Mi4tu6O/216rq28C3k3wOuApYqaE/ZMzvAnbWaMJ7NslTwI8DD0+mxYlb1Pw6F6Z3htzaYS9wc/sUfBPw31V1dNKNLqIFx5zkdcAngHeu4LO+cQuOuaour6r1VbUe+CvgN1dw4MOw3+37gZ9LsjrJ9zK6a+3jE+5zMQ0Z8zOM/mdDkkuBHwO+OtEuJ2tR82vFn+nXKW7tkOQ32vMfYnQlx/XALPA/jM4UVqyBY/4D4AeAu9qZ7/FawXcoHDjmc8qQMVfV40k+A3wZ+A7w4aqa99K/lWDgz/mPgHuSHGQ09fGeqlqxt1xO8jHgWuDiJIeB9wGvgKXJL2/DIEkdORemdyRJAxn6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSP/B4YZa6gMsX0dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visdrone_cbbox = np.concatenate(list_visdrone_cbbox, 0)\n",
    "visdrone_cbbox.shape\n",
    "plt.hist(visdrone_cbbox[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend 553 553 553\n"
     ]
    }
   ],
   "source": [
    "input_list_all = list_visdrone_image_arr\n",
    "bbox_list_all = list_visdrone_cbbox\n",
    "print('extend', len(list_visdrone_image_arr), len(input_list_all), len(bbox_list_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.rand(len(visdrone_categories), 3)\n",
    "def visualize_detections_simple(\n",
    "    image, boxes, classes, figsize=(12, 12),\n",
    "):\n",
    "    \"\"\"Visualize Detections\"\"\"\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    boxes_width = boxes[:, 2] - boxes[:, 0]\n",
    "    box_min_width = np.min(boxes_width)\n",
    "    box_mean_width = np.mean(boxes_width)\n",
    "    box_max_width = np.max(boxes_width)\n",
    "    title = str.format('(%dx%d) %d box, height:min:%d mean:%d max:%d' \n",
    "                       %(img_h, img_w, len(boxes), box_min_width, box_mean_width, box_max_width))\n",
    "    plt.title(title)\n",
    "    \n",
    "    for box, cls in zip(boxes, classes):\n",
    "        x1, y1, x2, y2 = box        \n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        cls = int(cls)\n",
    "        color = colors[cls]\n",
    "        patch = plt.Rectangle(\n",
    "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=1\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "        ax.text(\n",
    "            x1, y1, str(cls), bbox={\"facecolor\": color, \"alpha\": 0.4}, clip_box=ax.clipbox, clip_on=True,\n",
    "        )\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(X, BBOX, stride=1):\n",
    "    for i in range(len(X)):\n",
    "        if i%stride==0:\n",
    "            img_arr = input_list_all[i]\n",
    "            sample_box = bbox_list_all[i]\n",
    "            label = sample_box[:, 4]\n",
    "            bbox = sample_box[:, :4]\n",
    "\n",
    "            h, w, c = img_arr.shape\n",
    "            scale = np.array((w, h, w, h), dtype=np.float)\n",
    "            scale = np.reshape(scale, (1, 4))\n",
    "            bbox_norm = bbox.astype(np.float) * scale\n",
    "            #print('bbox_norm', bbox, bbox_norm)\n",
    "            ax = visualize_detections_simple(img_arr,bbox_norm,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(input_list_all, bbox_list_all, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
